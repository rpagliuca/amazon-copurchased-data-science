{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Copurchased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Python notebook created using \"jupyter\".\n",
    "\n",
    "Author: Rafael J. P. dos Santos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the parameter below to set the maximum number of edges to be read from the CSV containing edges (links)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:03.354285Z",
     "start_time": "2018-09-10T08:10:03.349646Z"
    },
    "cell_style": "center",
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "max_edges = 15000 # Set quantity to read from file\n",
    "edges_csv_file = \"data/20180812_links\"\n",
    "nodes_csv_file = \"data/20180812_nodes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the Python libraries that we will need throughout the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.117966Z",
     "start_time": "2018-09-10T08:10:03.443103Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read only first lines of datafile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to slowness in calculating centrality measures, we use the parameter provided in the beggining of the script to limit the number of edges we will read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.311923Z",
     "start_time": "2018-09-10T08:10:04.119978Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "total_line_count = 0\n",
    "with open(edges_csv_file, 'rb') as f:\n",
    "    f.readline()   # skip first line / header\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        if not (max_edges > 0 and len(lines) >= max_edges):\n",
    "            lines.append(line)\n",
    "        total_line_count += 1\n",
    "G = nx.parse_edgelist(lines, delimiter=',', nodetype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.317305Z",
     "start_time": "2018-09-10T08:10:04.313525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 15000 edges out of 229338 available (6.54% of data)\n"
     ]
    }
   ],
   "source": [
    "print \"Using %d edges out of %d available (%.2f%% of data)\" % (len(lines), total_line_count, len(lines)/total_line_count * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate nodes centrality measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our NetworkX graph, let's calculate some centrality measures for every node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.341845Z",
     "start_time": "2018-09-10T08:10:04.318791Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centrality_measures = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.368985Z",
     "start_time": "2018-09-10T08:10:04.343857Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centrality_measures[\"degree\"] = nx.degree(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:04.494842Z",
     "start_time": "2018-09-10T08:10:04.370707Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centrality_measures[\"eigenvector_centrality\"] = nx.eigenvector_centrality_numpy(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Approximate betweenness centrality (current flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:08.732111Z",
     "start_time": "2018-09-10T08:10:04.496935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "centrality_measures[\"betweenness_centrality\"] = nx.approximate_current_flow_betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Closeness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T14:15:29.579010Z",
     "start_time": "2018-08-12T14:09:40.277456Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Very slow!\n",
    "centrality_measures[\"closeness_centrality\"] = nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "source": [
    "#### Betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-12T14:30:59.943012Z",
     "start_time": "2018-08-12T14:15:29.580763Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Very slow!\n",
    "centrality_measures[\"betweenness_centrality\"] = nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load node properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the CSV containing the nodes data (title, price) into a Pandas dataframe, and append the centrality measures calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:08.815312Z",
     "start_time": "2018-09-10T08:10:08.733413Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(nodes_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:08.933777Z",
     "start_time": "2018-09-10T08:10:08.816714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add columns to dataframe\n",
    "def merge_columns(dataframe, data):\n",
    "    df = dataframe.copy()\n",
    "    for col in data:\n",
    "        rows = []\n",
    "        for item in data[col].items():\n",
    "            rows.append({\"id\": item[0], col: item[1]})\n",
    "        df = df.merge(pd.DataFrame(rows))\n",
    "    return df\n",
    "\n",
    "df = merge_columns(df, centrality_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's convert some fields to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.005858Z",
     "start_time": "2018-09-10T08:10:08.935371Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'category1',\n",
    "    'category2',\n",
    "    'category3',\n",
    "    'category4',\n",
    "    'category5',\n",
    "    'category6',\n",
    "    'category7',\n",
    "    'category8',\n",
    "    'category9',\n",
    "    'category10',\n",
    "    'language',\n",
    "    'coverType',\n",
    "    'publisher',\n",
    "    'rankingCategory'\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    'degree',\n",
    "    'eigenvector_centrality',\n",
    "    #'closeness_centrality',\n",
    "    'betweenness_centrality',\n",
    "    'ranking',\n",
    "    'reviewCount',\n",
    "    'pages',\n",
    "    'weight',\n",
    "    'height',\n",
    "    'width',\n",
    "    'depth',\n",
    "    'rating'\n",
    "]\n",
    "\n",
    "df = df.replace(\"<<MISSING_DATA>>\", np.NaN)\n",
    "df[numeric_features] = df[numeric_features].apply(pd.to_numeric)\n",
    "df[['price']] = df[['price']].apply(pd.to_numeric)\n",
    "\n",
    "for feature in numeric_features:\n",
    "    df[feature].fillna(df[feature].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove nodes without price and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.030901Z",
     "start_time": "2018-09-10T08:10:09.007261Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df[\"price\"].isnull()].index)\n",
    "df = df.drop(df[df[\"price\"] > 500].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.053633Z",
     "start_time": "2018-09-10T08:10:09.032362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'title', u'url', u'authors', u'coverType', u'publisher',\n",
       "       u'edition', u'publicationDate', u'rankingCategory', u'category1',\n",
       "       u'category2', u'category3', u'category4', u'category5', u'category6',\n",
       "       u'category7', u'category8', u'category9', u'category10', u'isbn10',\n",
       "       u'isbn13', u'language', u'postProcessed', u'price', u'ranking',\n",
       "       u'pages', u'reviewCount', u'rating', u'width', u'height', u'depth',\n",
       "       u'weight', u'eigenvector_centrality', u'degree',\n",
       "       u'betweenness_centrality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have a summary of the Pandas dataframe. We can see the number of nodes that we are actually analyzing, which depends on the max_edges parameter defined before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.226342Z",
     "start_time": "2018-09-10T08:10:09.055912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>coverType</th>\n",
       "      <th>publisher</th>\n",
       "      <th>edition</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>rankingCategory</th>\n",
       "      <th>category1</th>\n",
       "      <th>...</th>\n",
       "      <th>pages</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>rating</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depth</th>\n",
       "      <th>weight</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>degree</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>3070</td>\n",
       "      <td>3045</td>\n",
       "      <td>3045</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346</td>\n",
       "      <td>2922</td>\n",
       "      <td>2882</td>\n",
       "      <td>...</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3.070000e+03</td>\n",
       "      <td>3070.000000</td>\n",
       "      <td>3070.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3014</td>\n",
       "      <td>3070</td>\n",
       "      <td>2319</td>\n",
       "      <td>8</td>\n",
       "      <td>382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Macroeconomia</td>\n",
       "      <td>https://www.amazon.com.br/dp/9724418553/</td>\n",
       "      <td>Vários Autores (Autor)</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Companhia das Letras</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 de janeiro de 2014</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>2629</td>\n",
       "      <td>192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2922</td>\n",
       "      <td>2882</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2465.511075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>368.999853</td>\n",
       "      <td>13.951694</td>\n",
       "      <td>4.469695</td>\n",
       "      <td>15.464900</td>\n",
       "      <td>22.448944</td>\n",
       "      <td>2.147453</td>\n",
       "      <td>441.911335</td>\n",
       "      <td>4.059117e-03</td>\n",
       "      <td>7.702606</td>\n",
       "      <td>0.002531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2176.371452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>243.904988</td>\n",
       "      <td>34.035873</td>\n",
       "      <td>0.534578</td>\n",
       "      <td>2.570196</td>\n",
       "      <td>2.584363</td>\n",
       "      <td>1.202483</td>\n",
       "      <td>205.124700</td>\n",
       "      <td>1.587279e-02</td>\n",
       "      <td>17.326353</td>\n",
       "      <td>0.008660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>5.842757e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>896.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>209.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>13.800000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>4.509963e-06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>449.233179</td>\n",
       "      <td>1.322924e-05</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3215.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>456.000000</td>\n",
       "      <td>13.873001</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>544.000000</td>\n",
       "      <td>1.293926e-04</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.001707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9996.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4424.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>998.000000</td>\n",
       "      <td>1.928515e-01</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>0.150946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id          title                                       url  \\\n",
       "count   3070.000000           3070                                      3070   \n",
       "unique          NaN           3014                                      3070   \n",
       "top             NaN  Macroeconomia  https://www.amazon.com.br/dp/9724418553/   \n",
       "freq            NaN              5                                         1   \n",
       "mean    2465.511075            NaN                                       NaN   \n",
       "std     2176.371452            NaN                                       NaN   \n",
       "min        1.000000            NaN                                       NaN   \n",
       "25%      896.250000            NaN                                       NaN   \n",
       "50%     2100.000000            NaN                                       NaN   \n",
       "75%     3215.750000            NaN                                       NaN   \n",
       "max     9996.000000            NaN                                       NaN   \n",
       "\n",
       "                       authors   coverType             publisher  edition  \\\n",
       "count                     3070        3045                  3045      0.0   \n",
       "unique                    2319           8                   382      NaN   \n",
       "top     Vários Autores (Autor)  Capa comum  Companhia das Letras      NaN   \n",
       "freq                        33        2629                   192      NaN   \n",
       "mean                       NaN         NaN                   NaN      NaN   \n",
       "std                        NaN         NaN                   NaN      NaN   \n",
       "min                        NaN         NaN                   NaN      NaN   \n",
       "25%                        NaN         NaN                   NaN      NaN   \n",
       "50%                        NaN         NaN                   NaN      NaN   \n",
       "75%                        NaN         NaN                   NaN      NaN   \n",
       "max                        NaN         NaN                   NaN      NaN   \n",
       "\n",
       "             publicationDate rankingCategory category1          ...            \\\n",
       "count                    346            2922      2882          ...             \n",
       "unique                   287               1         1          ...             \n",
       "top     1 de janeiro de 2014          Livros    Livros          ...             \n",
       "freq                       5            2922      2882          ...             \n",
       "mean                     NaN             NaN       NaN          ...             \n",
       "std                      NaN             NaN       NaN          ...             \n",
       "min                      NaN             NaN       NaN          ...             \n",
       "25%                      NaN             NaN       NaN          ...             \n",
       "50%                      NaN             NaN       NaN          ...             \n",
       "75%                      NaN             NaN       NaN          ...             \n",
       "max                      NaN             NaN       NaN          ...             \n",
       "\n",
       "              pages  reviewCount       rating        width       height  \\\n",
       "count   3070.000000  3070.000000  3070.000000  3070.000000  3070.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean     368.999853    13.951694     4.469695    15.464900    22.448944   \n",
       "std      243.904988    34.035873     0.534578     2.570196     2.584363   \n",
       "min        4.000000     1.000000     1.000000     2.600000    10.000000   \n",
       "25%      209.250000     2.000000     4.473275    13.800000    20.800000   \n",
       "50%      316.000000     9.000000     4.473275    15.500000    22.800000   \n",
       "75%      456.000000    13.873001     4.900000    16.200000    23.400000   \n",
       "max     4424.000000   755.000000     5.000000    30.400000    37.800000   \n",
       "\n",
       "              depth       weight  eigenvector_centrality       degree  \\\n",
       "count   3070.000000  3070.000000            3.070000e+03  3070.000000   \n",
       "unique          NaN          NaN                     NaN          NaN   \n",
       "top             NaN          NaN                     NaN          NaN   \n",
       "freq            NaN          NaN                     NaN          NaN   \n",
       "mean       2.147453   441.911335            4.059117e-03     7.702606   \n",
       "std        1.202483   205.124700            1.587279e-02    17.326353   \n",
       "min        0.200000    18.100000            5.842757e-08     1.000000   \n",
       "25%        1.400000   299.000000            4.509963e-06     1.000000   \n",
       "50%        2.000000   449.233179            1.322924e-05     2.000000   \n",
       "75%        2.600000   544.000000            1.293926e-04     5.000000   \n",
       "max       16.000000   998.000000            1.928515e-01   198.000000   \n",
       "\n",
       "       betweenness_centrality  \n",
       "count             3070.000000  \n",
       "unique                    NaN  \n",
       "top                       NaN  \n",
       "freq                      NaN  \n",
       "mean                 0.002531  \n",
       "std                  0.008660  \n",
       "min                  0.000000  \n",
       "25%                  0.000000  \n",
       "50%                  0.000214  \n",
       "75%                  0.001707  \n",
       "max                  0.150946  \n",
       "\n",
       "[11 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can inspect the first rows of data, containing title, price, degree and other centrality measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.276480Z",
     "start_time": "2018-09-10T08:10:09.227635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>authors</th>\n",
       "      <th>coverType</th>\n",
       "      <th>publisher</th>\n",
       "      <th>edition</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>rankingCategory</th>\n",
       "      <th>category1</th>\n",
       "      <th>...</th>\n",
       "      <th>pages</th>\n",
       "      <th>reviewCount</th>\n",
       "      <th>rating</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>depth</th>\n",
       "      <th>weight</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>degree</th>\n",
       "      <th>betweenness_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Stanford Mathematics Problem Book: With Hi...</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486469247/</td>\n",
       "      <td>George Polya (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19 de fevereiro de 2009</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>19</td>\n",
       "      <td>0.003829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fourier Series</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486633179/</td>\n",
       "      <td>Georgi P. Tolstov (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 de junho de 1976</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>352.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>14.6</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>363.0</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>62</td>\n",
       "      <td>0.002080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Probability Theory: A Concise Course</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486635449/</td>\n",
       "      <td>Y. A. Rozanov (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.873001</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>14.4</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.034535</td>\n",
       "      <td>59</td>\n",
       "      <td>0.007333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Vectors, Tensors and the Basic Equations of Fl...</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486661105/</td>\n",
       "      <td>Rutherford Aris (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>320.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>381.0</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>18</td>\n",
       "      <td>0.002377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ordinary Differential Equations</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486649407/</td>\n",
       "      <td>Morris Tenenbaum (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>848.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>0.074795</td>\n",
       "      <td>88</td>\n",
       "      <td>0.011914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>The Variational Principles of Mechanics</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486650677/</td>\n",
       "      <td>Cornelius Lanczos (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>418.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>581.0</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>43</td>\n",
       "      <td>0.006224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>A First Look at Perturbation Theory</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486675513/</td>\n",
       "      <td>James G. Simmonds (Autor)</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications Inc.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>13.873001</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>13.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Thermodynamics and the Kinetic Theory of Gases...</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486414612/</td>\n",
       "      <td>Wolfgang Pauli (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 de outubro de 2010</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>10</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mechanics</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486607542/</td>\n",
       "      <td>Jacob P. Den Hartog (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 de junho de 1961</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>480.0</td>\n",
       "      <td>13.873001</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>13.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.019512</td>\n",
       "      <td>23</td>\n",
       "      <td>0.001077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Statistical Thermodynamics</td>\n",
       "      <td>https://www.amazon.com.br/dp/0486661016/</td>\n",
       "      <td>Erwin Schrodinger (Autor),</td>\n",
       "      <td>Capa comum</td>\n",
       "      <td>Dover Publications</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Livros</td>\n",
       "      <td>Livros</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>13.873001</td>\n",
       "      <td>4.473275</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.007206</td>\n",
       "      <td>15</td>\n",
       "      <td>0.003416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1  The Stanford Mathematics Problem Book: With Hi...   \n",
       "1   2                                     Fourier Series   \n",
       "2   3               Probability Theory: A Concise Course   \n",
       "3   4  Vectors, Tensors and the Basic Equations of Fl...   \n",
       "4   5                    Ordinary Differential Equations   \n",
       "5   6            The Variational Principles of Mechanics   \n",
       "6   7                A First Look at Perturbation Theory   \n",
       "7   8  Thermodynamics and the Kinetic Theory of Gases...   \n",
       "8   9                                          Mechanics   \n",
       "9  10                         Statistical Thermodynamics   \n",
       "\n",
       "                                        url                       authors  \\\n",
       "0  https://www.amazon.com.br/dp/0486469247/         George Polya (Autor),   \n",
       "1  https://www.amazon.com.br/dp/0486633179/    Georgi P. Tolstov (Autor),   \n",
       "2  https://www.amazon.com.br/dp/0486635449/        Y. A. Rozanov (Autor),   \n",
       "3  https://www.amazon.com.br/dp/0486661105/      Rutherford Aris (Autor),   \n",
       "4  https://www.amazon.com.br/dp/0486649407/     Morris Tenenbaum (Autor),   \n",
       "5  https://www.amazon.com.br/dp/0486650677/    Cornelius Lanczos (Autor),   \n",
       "6  https://www.amazon.com.br/dp/0486675513/     James G. Simmonds (Autor)   \n",
       "7  https://www.amazon.com.br/dp/0486414612/       Wolfgang Pauli (Autor),   \n",
       "8  https://www.amazon.com.br/dp/0486607542/  Jacob P. Den Hartog (Autor),   \n",
       "9  https://www.amazon.com.br/dp/0486661016/    Erwin Schrodinger (Autor),   \n",
       "\n",
       "    coverType                publisher  edition          publicationDate  \\\n",
       "0  Capa comum       Dover Publications      NaN  19 de fevereiro de 2009   \n",
       "1  Capa comum       Dover Publications      NaN       1 de junho de 1976   \n",
       "2  Capa comum       Dover Publications      NaN                      NaN   \n",
       "3  Capa comum       Dover Publications      NaN                      NaN   \n",
       "4  Capa comum       Dover Publications      NaN                      NaN   \n",
       "5  Capa comum       Dover Publications      NaN                      NaN   \n",
       "6  Capa comum  Dover Publications Inc.      NaN                      NaN   \n",
       "7  Capa comum       Dover Publications      NaN    18 de outubro de 2010   \n",
       "8  Capa comum       Dover Publications      NaN       1 de junho de 1961   \n",
       "9  Capa comum       Dover Publications      NaN                      NaN   \n",
       "\n",
       "  rankingCategory category1          ...            pages reviewCount  \\\n",
       "0          Livros    Livros          ...             68.0    1.000000   \n",
       "1          Livros    Livros          ...            352.0    3.000000   \n",
       "2          Livros    Livros          ...            160.0   13.873001   \n",
       "3          Livros    Livros          ...            320.0    2.000000   \n",
       "4          Livros    Livros          ...            848.0    4.000000   \n",
       "5          Livros    Livros          ...            418.0    1.000000   \n",
       "6          Livros    Livros          ...            160.0   13.873001   \n",
       "7          Livros    Livros          ...            160.0    2.000000   \n",
       "8          Livros    Livros          ...            480.0   13.873001   \n",
       "9          Livros    Livros          ...            112.0   13.873001   \n",
       "\n",
       "     rating width height depth  weight  eigenvector_centrality  degree  \\\n",
       "0  4.000000  14.0   21.0   0.6   181.0                0.012593      19   \n",
       "1  4.600000  14.6   21.0   1.9   363.0                0.053497      62   \n",
       "2  4.473275  14.4   20.8   0.8   200.0                0.034535      59   \n",
       "3  4.500000  13.7   21.5   1.6   381.0                0.011868      18   \n",
       "4  4.500000  13.8   21.8   4.0   939.0                0.074795      88   \n",
       "5  5.000000  13.8   21.5   2.2   581.0                0.050004      43   \n",
       "6  4.473275  13.7   21.5   0.8   159.0                0.008733       9   \n",
       "7  5.000000  13.8   21.6   1.0   159.0                0.004537      10   \n",
       "8  4.473275  13.6   20.3   2.3   522.0                0.019512      23   \n",
       "9  4.473275  14.0   20.3   1.3   159.0                0.007206      15   \n",
       "\n",
       "  betweenness_centrality  \n",
       "0               0.003829  \n",
       "1               0.002080  \n",
       "2               0.007333  \n",
       "3               0.002377  \n",
       "4               0.011914  \n",
       "5               0.006224  \n",
       "6               0.000348  \n",
       "7               0.005175  \n",
       "8               0.001077  \n",
       "9               0.003416  \n",
       "\n",
       "[10 rows x 35 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest using degree as feature, price as target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.311424Z",
     "start_time": "2018-09-10T08:10:09.279024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_with_dummies = pd.get_dummies(df[numeric_features + categorical_features + ['price']],columns=categorical_features,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.364795Z",
     "start_time": "2018-09-10T08:10:09.314511Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = list(df_with_dummies.drop(columns = ['price']))\n",
    "features = np.array(df_with_dummies.drop(columns = ['price']))\n",
    "target = np.array(df_with_dummies['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average price as baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to have a baseline, so we can validate our predictions after running our model. One easy choice for baseline is the average price of a book.\n",
    "\n",
    "We have an average price around R\\$43, so this means that a very easy prediction would be to always guess R$43 for the price of any book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-10T08:10:09.370779Z",
     "start_time": "2018-09-10T08:10:09.366961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average price: R$ 68.1872247557\n"
     ]
    }
   ],
   "source": [
    "average_target = np.average(target)\n",
    "print \"Average price: R$\", average_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our dataset into two sets: train and test. We use the first to train or model, and we use the second to test the precision of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Features Shape:', (2302, 1061))\n",
      "('Training Labels Shape:', (2302,))\n",
      "('Testing Features Shape:', (768, 1061))\n",
      "('Testing Labels Shape:', (768,))\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_target, test_target \\\n",
    "    = train_test_split(features, target, test_size = 0.25)\n",
    "\n",
    "# Summary\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_target.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a random forest model with 500 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "rf = RandomForestRegressor(n_estimators = 500)\n",
    "# Train\n",
    "rf.fit(train_features, train_target);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  List of most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.564Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = zip(feature_list, rf.feature_importances_)\n",
    "importance.sort(key=lambda x:-x[1])\n",
    "pd.DataFrame(importance).head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Preço previsto vs. Preço real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.605Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8), dpi=130)\n",
    "plt.scatter(test_target, predictions, 100, alpha=0.05, edgecolors=\"none\")\n",
    "baseline = [0, np.max(test_target)]\n",
    "plt.plot(baseline, baseline, \"--\", color=\"green\", label = u\"Preço previsto = Preço real\")\n",
    "ax = plt.gca()\n",
    "ax.set_ylabel(u\"Preço previsto (R$)\")\n",
    "ax.set_xlabel(u\"Preço real (R$)\")\n",
    "ax.legend()\n",
    "plt.title(u\"Preço previsto vs. Preço real\")\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "#plt.xlim(0, 150)\n",
    "#plt.ylim(0, 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the errors obtained by our predictions against the errors provided by the baseline (average price). Our prediction errors should be less than the baseline errors to consider the model successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_target)\n",
    "errors_baseline = abs(average_target - test_target)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean absolute prediction error: R$', round(np.mean(errors), 2))\n",
    "print('Mean absolute error using average: R$',\n",
    "      round(np.mean(errors_baseline), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worst predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can inspect the rows with the biggest prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.842Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"degree\": test_features.tolist(),\n",
    "    \"target\": test_target,\n",
    "    \"prediction\": predictions,\n",
    "    \"error\": errors,\n",
    "    \"errors_baseline\": errors_baseline\n",
    "}\n",
    "predicted_df = pd.DataFrame(data = data)\n",
    "predicted_df.sort_values('error', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.879Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_df.sort_values('error', ascending = True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-09-10T08:10:04.882Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-11T12:29:52.886454Z",
     "start_time": "2018-08-11T12:29:49.054278Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[0]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot',\n",
    "                feature_names = feature_list, rounded = True)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/image.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "591px",
    "width": "459px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "241px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
